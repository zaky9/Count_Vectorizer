{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4baac59",
   "metadata": {},
   "source": [
    "## Count Vectorizer \n",
    "Four common text-to-vector transformation methods are compared for their accuracy. These are Stopwords, Simple, Lemmatization, and Stemming. The dataset used are from BBC full text documents that can be downloaded at:\n",
    "__[Kaggle](https://www.kaggle.com/shivamkushwaha/bbc-full-text-document-classification)__ or __[lazyprogrammer](https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv)__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a85ff6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\ZAKY-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\ZAKY-\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ZAKY-PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from  nltk.corpus import wordnet\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3579d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad sales boost Time Warner profit\\n\\nQuarterly...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dollar gains on Greenspan speech\\n\\nThe dollar...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High fuel prices hit BA's profits\\n\\nBritish A...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pernod takeover talk lifts Domecq\\n\\nShares in...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    labels\n",
       "0  Ad sales boost Time Warner profit\\n\\nQuarterly...  business\n",
       "1  Dollar gains on Greenspan speech\\n\\nThe dollar...  business\n",
       "2  Yukos unit buyer faces loan claim\\n\\nThe owner...  business\n",
       "3  High fuel prices hit BA's profits\\n\\nBritish A...  business\n",
       "4  Pernod takeover talk lifts Domecq\\n\\nShares in...  business"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/shivamkushwaha/bbc-full-text-document-classification\n",
    "# !wget -nc https://lazyprogrammer.me/course_files/nlp/bbc_text_cls.csv\n",
    "dataset = \"C:/Users/ZAKY-PC/Jupyter_proj/datasets/bbc_text_cls.csv\"\n",
    "df = pd.read_csv(dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552f903c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAEvCAYAAACHYI+LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYIUlEQVR4nO3df7RdZX3n8ffHxB9MYhMQexcNaFhIp8OYpSN3KdZO50ZaB6EVZopWywhYujKdwVErdqQz/aFr2dWoRax0qs0UF9GiEak2CNTKBOPvX6QqQagaMRYylFSBtPirk/qdP86TcrjeJDfJc+49uXm/1jorez/72Xs/5zxnP/ncffbZJ1WFJEmSDt0j5rsBkiRJC4XBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ0YrCRJkjpZPN8NADj22GNr5cqVI93Ht7/9bZYsWTLSfWg82fdHLvv+yGXfH7nmou+3bNnyzap6/EzLxiJYrVy5kltuuWWk+9i8eTNTU1Mj3YfGk31/5LLvj1z2/ZFrLvo+yTf2tsyPAiVJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6MVhJkiR1YrCSJEnqZCx+K3AubN2xiwsvvWG+m9HF9rVnzXcTJOmgrZyDsfiSVbtHPuY7FmsmnrGSJEnqZFbBKsn2JFuTfCHJLa3smCQ3Jflq+/foVp4kb0myLcmtSZ42yicgSZI0Lg7kjNXqqnpqVU22+UuBTVV1MrCpzQM8Fzi5PdYAb+3VWEmSpHF2KB8Fng2sb9PrgXOGyt9RA58Glic57hD2I0mSdFiYbbAq4ENJtiRZ08omquqeNv23wESbXgHcNbTu3a1MkiRpQZvttwJ/qqp2JPlR4KYkfz28sKoqSR3IjltAWwMwMTHB5s2bD2T1AzZx1OBbIgvBqF+rhebBBx/0NTtC2ffjaS7G4rkY831vjaf5Pu5nFayqakf7d2eS9wNPB+5NclxV3dM+6tvZqu8AThha/fhWNn2b64B1AJOTkzU1NXXQT2I2rrh6I5dtXRh3l9h+3tR8N+GwsnnzZkb9/tJ4su/H01zc+uaSVbtHPuY7Fo+n+T7u9/tRYJIlSR67Zxp4DnAbcB1wQat2AbCxTV8HnN++HXgasGvoI0NJkqQFazZxfgJ4f5I99d9VVR9M8jngmiQXAd8AXtDq3wicCWwDvgO8pHurJUmSxtB+g1VV3Qk8ZYbybwGnz1BewMVdWidJknQY8c7rkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sRgJUmS1InBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ0YrCRJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6MVhJkiR1YrCSJEnqxGAlSZLUicFKkiSpE4OVJElSJwYrSZKkTgxWkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sRgJUmS1InBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ0YrCRJkjoxWEmSJHVisJIkSerEYCVJktTJ4vlugCSNytYdu7jw0hvmuxldbF971nw3QdIseMZKkiSpE4OVJElSJwYrSZKkTmYdrJIsSvL5JNe3+ROTfCbJtiTvSfKoVv7oNr+tLV85orZLkiSNlQM5Y/Vy4I6h+dcDl1fVk4D7gYta+UXA/a388lZPkiRpwZtVsEpyPHAW8CdtPsCzgWtblfXAOW367DZPW356qy9JkrSgzfaM1ZuB/w78oM0/Dnigqna3+buBFW16BXAXQFu+q9WXJEla0PZ7H6skPwfsrKotSaZ67TjJGmANwMTEBJs3b+616RlNHAWXrNq9/4qHgVG/VgvNgw8+6Gt2hPK4H09z0Sdz0fcLqU+27tg1303o5sRli+a1b2Zzg9BnAc9LcibwGOBHgD8AlidZ3M5KHQ/saPV3ACcAdydZDCwDvjV9o1W1DlgHMDk5WVNTU4f4VPbtiqs3ctnWhXE/1O3nTc13Ew4rmzdvZtTvL40nj/vxNBc3bb1k1e6R9719Mp6uOmPJvI75+/0osKp+o6qOr6qVwAuBm6vqPODDwLmt2gXAxjZ9XZunLb+5qqprqyVJksbQodzH6tXAK5NsY3AN1ZWt/Ergca38lcClh9ZESZKkw8MBnSetqs3A5jZ9J/D0Gep8D3h+h7ZJkiQdVrzzuiRJUicGK0mSpE4WxtdldNhaOUffDpqLb7xsX3vWyPchSRpvnrGSJEnqxGAlSZLUicFKkiSpE4OVJElSJwYrSZKkTgxWkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sRgJUmS1InBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ0YrCRJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6MVhJkiR1YrCSJEnqxGAlSZLUicFKkiSpE4OVJElSJwYrSZKkTgxWkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sRgJUmS1InBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ0YrCRJkjrZb7BK8pgkn03yxSRfSvLaVn5iks8k2ZbkPUke1cof3ea3teUrR/wcJEmSxsJszlh9H3h2VT0FeCpwRpLTgNcDl1fVk4D7gYta/YuA+1v55a2eJEnSgrffYFUDD7bZR7ZHAc8Grm3l64Fz2vTZbZ62/PQk6dVgSZKkcTWra6ySLEryBWAncBPwNeCBqtrdqtwNrGjTK4C7ANryXcDjOrZZkiRpLKWqZl85WQ68H/gt4Kr2cR9JTgD+oqqenOQ24Iyqurst+xrwjKr65rRtrQHWAExMTJy6YcOGDk9n73bet4t7vzvSXcyZVSuWzXcTutm6Y9fI9zFxFHPS9wupXxYKj/vxtFCOe/tkPJ24bBFLly4d6T5Wr169paomZ1q2+EA2VFUPJPkw8ExgeZLF7azU8cCOVm0HcAJwd5LFwDLgWzNsax2wDmBycrKmpqYOpCkH7IqrN3LZ1gN6umNr+3lT892Ebi689IaR7+OSVbvnpO8XUr8sFB7342mhHPf2yXi66owljDpT7MtsvhX4+HamiiRHAT8L3AF8GDi3VbsA2Nimr2vztOU314GcFpMkSTpMzSbOHwesT7KIQRC7pqquT3I7sCHJ64DPA1e2+lcC70yyDbgPeOEI2i1JkjR29husqupW4N/MUH4n8PQZyr8HPL9L6yRJkg4j3nldkiSpE4OVJElSJwYrSZKkTgxWkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sRgJUmS1InBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ0YrCRJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6MVhJkiR1YrCSJEnqxGAlSZLUicFKkiSpE4OVJElSJwYrSZKkTgxWkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sRgJUmS1InBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ0YrCRJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVIn+w1WSU5I8uEktyf5UpKXt/JjktyU5Kvt36NbeZK8Jcm2JLcmedqon4QkSdI4mM0Zq93AJVV1CnAacHGSU4BLgU1VdTKwqc0DPBc4uT3WAG/t3mpJkqQxtN9gVVX3VNVftel/AO4AVgBnA+tbtfXAOW36bOAdNfBpYHmS43o3XJIkadykqmZfOVkJfBR4MvA3VbW8lQe4v6qWJ7keWFtVH2/LNgGvrqpbpm1rDYMzWkxMTJy6YcOGQ382+7Dzvl3c+92R7mLOrFqxbL6b0M3WHbtGvo+Jo5iTvl9I/bJQeNyPp4Vy3Nsn4+nEZYtYunTpSPexevXqLVU1OdOyxbPdSJKlwJ8Br6iqvx9kqYGqqiSzT2iDddYB6wAmJydramrqQFY/YFdcvZHLts766Y617edNzXcTurnw0htGvo9LVu2ek75fSP2yUHjcj6eFctzbJ+PpqjOWMOpMsS+z+lZgkkcyCFVXV9X7WvG9ez7ia//ubOU7gBOGVj++lUmSJC1os/lWYIArgTuq6k1Di64DLmjTFwAbh8rPb98OPA3YVVX3dGyzJEnSWJrNedJnAS8Gtib5Qiv7H8Ba4JokFwHfAF7Qlt0InAlsA74DvKRngyVJksbVfoNVuwg9e1l8+gz1C7j4ENslSZJ02PHO65IkSZ0YrCRJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6MVhJkiR1YrCSJEnqxGAlSZLUicFKkiSpE4OVJElSJwYrSZKkTgxWkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sRgJUmS1InBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ0YrCRJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6MVhJkiR1YrCSJEnqxGAlSZLUicFKkiSpE4OVJElSJwYrSZKkTgxWkiRJnew3WCV5e5KdSW4bKjsmyU1Jvtr+PbqVJ8lbkmxLcmuSp42y8ZIkSeNkNmesrgLOmFZ2KbCpqk4GNrV5gOcCJ7fHGuCtfZopSZI0/vYbrKrqo8B904rPBta36fXAOUPl76iBTwPLkxzXqa2SJElj7WCvsZqoqnva9N8CE216BXDXUL27W5kkSdKCl6raf6VkJXB9VT25zT9QVcuHlt9fVUcnuR5YW1Ufb+WbgFdX1S0zbHMNg48LmZiYOHXDhg0dns7e7bxvF/d+d6S7mDOrViyb7yZ0s3XHrpHvY+Io5qTvF1K/LBQe9+NpoRz39sl4OnHZIpYuXTrSfaxevXpLVU3OtGzxQW7z3iTHVdU97aO+na18B3DCUL3jW9kPqap1wDqAycnJmpqaOsimzM4VV2/ksq0H+3THy/bzpua7Cd1ceOkNI9/HJat2z0nfL6R+WSg87sfTQjnu7ZPxdNUZSxh1ptiXg/0o8DrggjZ9AbBxqPz89u3A04BdQx8ZSpIkLWj7jfNJ3g1MAccmuRv4HWAtcE2Si4BvAC9o1W8EzgS2Ad8BXjKCNkuSJI2l/QarqnrRXhadPkPdAi4+1EZJkiQdjrzzuiRJUicGK0mSpE4MVpIkSZ0YrCRJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6MVhJkiR1YrCSJEnqxGAlSZLUicFKkiSpE4OVJElSJwYrSZKkTgxWkiRJnRisJEmSOjFYSZIkdWKwkiRJ6sRgJUmS1InBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ0YrCRJkjoxWEmSJHVisJIkSerEYCVJktSJwUqSJKkTg5UkSVInBitJkqRODFaSJEmdGKwkSZI6MVhJkiR1YrCSJEnqxGAlSZLUicFKkiSpE4OVJElSJwYrSZKkTkYSrJKckeTLSbYluXQU+5AkSRo33YNVkkXA/wKeC5wCvCjJKb33I0mSNG5Gccbq6cC2qrqzqv4R2ACcPYL9SJIkjZVRBKsVwF1D83e3MkmSpAUtVdV3g8m5wBlV9Stt/sXAM6rqpdPqrQHWtNl/CXy5a0N+2LHAN0e8D40n+/7IZd8fuez7I9dc9P0Tq+rxMy1YPIKd7QBOGJo/vpU9TFWtA9aNYP8zSnJLVU3O1f40Puz7I5d9f+Sy749c8933o/go8HPAyUlOTPIo4IXAdSPYjyRJ0ljpfsaqqnYneSnwl8Ai4O1V9aXe+5EkSRo3o/gokKq6EbhxFNs+BHP2saPGjn1/5LLvj1z2/ZFrXvu++8XrkiRJRyp/0kaSJKmTsQxWSVYmue0Qt/FjSa7t1SaNVpJzDuYO/UmmkvzkLOo9b75+XinJ8iT/dT72fSRJsjnJZJu+sb3uD3vtHRc0bLbjh+bfoYyjSa5qt4KaE2MZrHqoqv9bVXP2QuqQncPgJ5BmLcliYArY78BYVddV1dqDatmhWw4YrOZQVZ1ZVQ8w7bV3XNAeBzJ+aCws5zAZR8c5WC1OcnWSO5Jcm+RfJNme5FiAJJNJNrfpf5fkC+3x+SSPHT7rleTCJO9L8sEkX03yhj07SfKcJJ9K8ldJ3ptkaStfm+T2JLcm+f1W9vwktyX5YpKPzvkrcphJ8p+SfLb1yx8nWZTkwSS/217DTyeZaH8xPg94Y6t7Unt8MMmWJB9L8hNtm1cleVuSzwDXAL8K/Fpb798m+fkkn2nvg/+TZKKtd2GSPxzaxluSfDLJnXv+kml/vX4kycZWvjbJee05bE1yUqv3+CR/luRz7fGsVv6aJG9vZ07uTPKy9lKsBU5qbXzjHHbBYa0dw389wzhweuvfre31fvQM6+4ZKx722k8bFxYl+f12TN+a5L+18h869jX/kixJckMbO25L8outn9/Q3gufTfKkVndlkptbH25K8oRWvs/xYx6fnvZv+rH86238vTXJa/dUSnJ+K/tikncOrf/T08f8kamqsXsAK4ECntXm3w68CtgOHNvKJoHNbfoDQ3WXMvi240rgtlZ2IXAnsAx4DPANBjcxPRb4KLCk1Xs18NvA4xjcCX7Pxf3L279bgRXDZT722of/qvXLI9v8HwHnt379+Vb2BuA32/RVwLlD628CTm7TzwBuHqp3PbCozb8GeNXQekcP9duvAJcNvQf+cGgb72Xwh8UpDH7bEgZ/vT4AHAc8msGNbV/blr0ceHObfhfwU236CcAdQ235ZFv3WOBbwCOH34s+Dug9NNM48JsMfjLrx1vZO4BXtOnNwGSb3t764GGvPQ8fF/4LcC2wuM0fs7dj38f8P4BfAP730Pyy1s//s82fD1zfpj8AXNCmfxn48za9z/HDx/g+ph27z2Hwzb+0cfx64KeBfw18hYdywjFD/f5DY/6oHiO53UInd1XVJ9r0nwIv20fdTwBvSnI18L6qujvJ9DqbqmoXQJLbgScyOLV4CvCJVv9RwKeAXcD3gCuTXM+g0/bs56ok1wDvO7Snt+CdDpwKfK69tkcBO4F/5KHXcwvws9NXzOCs4U8C7x3qx+GzEu+tqn/ay36PB96T5DgG/fn1vdT786r6AXD7nrNazeeq6p7Wjq8BH2rlW4HVbfpngFOG2vYjrc0AN1TV94HvJ9kJDG9bB276OPBbwNer6iutbD1wMfDmg9j2zwBvq6rdAFV1XwYfD8107Gv+bQUuS/J6BgHqY+0YfHdb/m7g8jb9TOA/tul3Mvgjbo99jR86PDynPT7f5pcCJwNPYdC/34TBMT20zt7G/O7GOVhNvw9EAbt56OPLx/zzgqq1SW4AzmQQkv49g8Fx2PeHpv+JwXMPcFNVvWj6zpM8nUE4OBd4KfDsqvrVJM8AzgK2JDm1qr51sE9wgQuwvqp+42GFyauq/QnBQ/0w3SOAB6rqqXvZ9rf3sd8rgDdV1XVJphj8RTqT4fdD9lL+g6H5Hwy19RHAaVX1sPdYG+Rnep/p4E0fBx5gcFZpNDsb3OD4h479Ue1Ps1dVX0nyNAbj/OuSbNqzaLjaLDa1r/FDh4cAv1dVf/ywwvZx/l7sbczvbpyvsXpCkme26V8CPs7gtO+prewX9lRMclJVba2q1zP4SZ2fmOU+Pg08a+hz+SVJfrydfVhWgxud/hqDFLxnP5+pqt8G/o6H/yaiHm4TcG6SHwVIckySJ+6j/j8AjwWoqr8Hvp7k+W3dJHnK/tZrlvHQb1NecAjt35cPAf98ACd56n7qT2+jZm/6OHALsHLPMQu8GPjIPtbf12t/E/Cf21mqPe/RGY99zb8kPwZ8p6r+FHgj8LS26BeH/v1Um/4kg59TAzgP+NheNuuxefgY7qu/BH45D10TvaL9X3Mz8Pwkj2vlx8xHQ8c5WH0ZuDjJHQyum3kr8FrgD5LcwuBswB6v2HMBKvD/gL+YzQ6q6u8YXHvz7rbupxiEsscC17eyjwOvbKu8sV0keRuDA/eLh/gcF6yqup3B9TAfaq/jTQyuXdqbDcCvt4uST2IwGF6U5IvAl4Cz97LeB4D/MHTx6WsYfIS4hdH9uvnLgMl2geTtDC6A3at2VvMT7T3qxesHZvo4cDnwEgZ9vJXBmcS37W3l/bz2fwL8DXBre5/9Ens/9jX/VgGfTfIF4HeA17Xyo1t/vZxBGIbBHz4vaeUvbstmMn380JgaPpYZXELyLuBTbRy4FnhsDX4+73eBj7Rj+k3z0VbvvC5pLCVZyeBamifPd1s0npJsZ/CFhVH9ESUdsHE+YyVJknRY8YyVJElSJ56xkiRJ6sRgJUmS1InBSpIkqRODlSRJUicGK0mSpE4MVpIkSZ38f9OPUfNTQrStAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# assign input and label\n",
    "inputs = df['text']\n",
    "labels = df['labels']\n",
    "\n",
    "# plot histogram\n",
    "labels.hist(figsize=(10,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "563da6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test dataset: to check imbalance classes\n",
    "input_train, input_test, y_train, y_test = train_test_split(inputs, labels, random_state=123)\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "x_train = vectorizer.fit_transform(input_train)\n",
    "x_test = vectorizer.transform(input_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e482f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007695239935415004\n"
     ]
    }
   ],
   "source": [
    "# print(x_train)\n",
    "# observe the magnitude of sparse the matrix is\n",
    "# print((x_train != 0).sum()) # 337411 of non  zero values\n",
    "\n",
    "print((x_train != 0).sum()/ np.prod(x_train.shape)) # number of non-zero elements/ total number of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f6f34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9922062350119905\n",
      "test score:  0.9712746858168761\n"
     ]
    }
   ],
   "source": [
    "# Without transformation to vector\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n",
    "print(\"train score: \",model.score(x_train,y_train))\n",
    "print(\"test score: \", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dd18285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9928057553956835\n",
      "test score:  0.9766606822262118\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Stopwords\n",
    "vectorizer_stopwords = CountVectorizer(stop_words='english')\n",
    "x_train_SW = vectorizer_stopwords.fit_transform(input_train)\n",
    "x_test_SW = vectorizer_stopwords.transform(input_test)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train_SW, y_train)\n",
    "\n",
    "print(\"train score: \",model.score(x_train_SW,y_train))\n",
    "print(\"test score: \", model.score(x_test_SW, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c9d622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9952038369304557\n",
      "test score:  0.9712746858168761\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Simple tokenizer\n",
    "def simple_tokenizer(s):\n",
    "    return s.split() # using split function\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer = simple_tokenizer)\n",
    "x_train = vectorizer.fit_transform(input_train)\n",
    "x_test = vectorizer.transform(input_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(\"train score: \",model.score(x_train,y_train))\n",
    "print(\"test score: \", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca28e8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9922062350119905\n",
      "test score:  0.9676840215439856\n"
     ]
    }
   ],
   "source": [
    "# Method 3: LemmaTokenizer\n",
    "\n",
    "# automate the pos tagging\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "    \n",
    "# used to define the class for tokenizing and limiting each documents\n",
    "# output is a list containing each lemmatize the word in the input document\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self): # initializer by instantiating WordNetLemmatizer object\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc): # calling the documents to be tokenize\n",
    "        tokens = word_tokenize(doc) # convert documents into token (similar to string split)\n",
    "        words_and_tags = nltk.pos_tag(tokens) # to obtain the parts of speech tags\n",
    "        return [self.wnl.lemmatize(word, pos= get_wordnet_pos(tag)) for word, tag in words_and_tags] # to loop every words and tag to lemmatize function\n",
    "                                                                                                     \n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer = LemmaTokenizer())\n",
    "x_train = vectorizer.fit_transform(input_train)\n",
    "x_test = vectorizer.transform(input_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(\"train score: \",model.score(x_train,y_train))\n",
    "print(\"test score: \", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b04807fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score:  0.9892086330935251\n",
      "test score:  0.9694793536804309\n"
     ]
    }
   ],
   "source": [
    "# Method 4: StemTokenizer\n",
    "\n",
    "class StemTokenizer:\n",
    "    def __init__(self):\n",
    "        self.porter = PorterStemmer() # initiate  porterstemmer\n",
    "    def __call__(self, doc):\n",
    "        tokens = word_tokenize(doc)\n",
    "        return [self.porter.stem(t) for t in tokens]\n",
    "    \n",
    "vectorizer = CountVectorizer(tokenizer = StemTokenizer())\n",
    "x_train = vectorizer.fit_transform(input_train)\n",
    "x_test = vectorizer.transform(input_test)\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print(\"train score: \",model.score(x_train,y_train))\n",
    "print(\"test score: \", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b7832",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "&nbsp;\n",
    "<div style=\"text-align: justify\">\n",
    "All of the methods demonstrated similar accuracy. Stopword outperformed other methods in test score accuracy (0.98), followed by the simple split method (0.97). Both Lemmatization and Stemming methods performed poorly compared to Stopword and Simple split method. In addition, not transforming the word to vector shows better performance than both approaches. Therefore, based on these observations, we can conclude that testing all word-to-vector (Count vectorizer) transformations is required. Additionally, the Complex model (Lemmatization & Stemming) does not mean it is the best approach for a given dataset.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09df1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
